{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 640) (360, 640, 3)\n",
      "[208 246 231 269] [208 246 218 256] 0.8109640831758034\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 16:38:17.050 python[82440:1941251] +[IMKClient subclass]: chose IMKClient_Legacy\n",
      "2024-10-09 16:38:17.050 python[82440:1941251] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 640) (360, 640, 3)\n",
      "[208 246 231 269] [208 264 208 264] 1.0\n",
      "<class 'numpy.ndarray'>\n",
      "(360, 640) (360, 640, 3)\n",
      "[208 246 231 269] [208 246 231 269] 0.0\n",
      "<class 'numpy.ndarray'>\n",
      "(360, 640) (360, 640, 3)\n",
      "[198 246 221 269] [198 254 199 254] 1.0\n",
      "<class 'numpy.ndarray'>\n",
      "(360, 640) (360, 640, 3)\n",
      "[198 246 221 269] [198 246 221 269] 0.0\n",
      "<class 'numpy.ndarray'>\n",
      "(360, 640) (360, 640, 3)\n",
      "[193 241 216 264] [193 252 193 252] 1.0\n",
      "<class 'numpy.ndarray'>\n",
      "(360, 640) (360, 640, 3)\n",
      "[193 241 216 264] [193 241 216 264] 0.0\n",
      "<class 'numpy.ndarray'>\n",
      "(360, 640) (360, 640, 3)\n",
      "[188 236 211 259] [188 236 211 259] 0.0\n",
      "<class 'numpy.ndarray'>\n",
      "(360, 640) (360, 640, 3)\n",
      "[183 231 206 254] [183 231 206 254] 0.0\n",
      "<class 'numpy.ndarray'>\n",
      "(360, 640) (360, 640, 3)\n",
      "[178 226 201 249] [183 226 183 226] 1.0\n",
      "<class 'numpy.ndarray'>\n",
      "(360, 640) (360, 640, 3)\n",
      "[178 226 201 249] [178 226 201 249] 0.0\n",
      "<class 'numpy.ndarray'>\n",
      "(360, 640) (360, 640, 3)\n",
      "[183 231 206 254] [183 231 206 254] 0.0\n",
      "<class 'numpy.ndarray'>\n",
      "(360, 640) (360, 640, 3)\n",
      "[178 226 201 249] [178 226 201 249] 0.0\n",
      "<class 'numpy.ndarray'>\n",
      "(360, 640) (360, 640, 3)\n",
      "[173 221 196 244] [173 221 196 244] 0.0\n",
      "<class 'numpy.ndarray'>\n",
      "(360, 640) (360, 640, 3)\n",
      "[163 221 186 244] [163 221 186 244] 0.0\n",
      "<class 'numpy.ndarray'>\n",
      "(360, 640) (360, 640, 3)\n",
      "[163 221 186 244] [163 221 186 244] 0.0\n",
      "<class 'numpy.ndarray'>\n",
      "(360, 640) (360, 640, 3)\n",
      "[168 226 191 249] [168 226 191 249] 0.0\n",
      "<class 'numpy.ndarray'>\n",
      "(360, 640) (360, 640, 3)\n",
      "[163 221 186 244] [163 221 186 244] 0.0\n",
      "<class 'numpy.ndarray'>\n",
      "(360, 640) (360, 640, 3)\n",
      "[163 221 167 225] [163 221 167 225] 0.0\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import ndimage\n",
    "\n",
    "def compute_likelihood_map(frame, object_hypothesis, object_model):\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    object_hist = object_model['histogram']\n",
    "    likelihood_map = cv2.calcBackProject([hsv], [0, 1], object_hist, [0, 180, 0, 256], 1)\n",
    "    likelihood_map = cv2.normalize(likelihood_map, None, 0, 1, cv2.NORM_MINMAX)\n",
    "    return likelihood_map\n",
    "\n",
    "def compute_cumulative_histograms(likelihood_map, object_region, surrounding_region):\n",
    "    h_o = np.histogram(likelihood_map[tuple(object_region)], bins=256, range=(0, 1))[0]\n",
    "    h_s = np.histogram(likelihood_map[tuple(surrounding_region)], bins=256, range=(0, 1))[0]\n",
    "    c_o = np.cumsum(h_o) / np.sum(h_o)\n",
    "    c_s = np.cumsum(h_s) / np.sum(h_s)\n",
    "    return c_o, c_s\n",
    "\n",
    "def adaptive_threshold(c_o, c_s):\n",
    "    \n",
    "    valid_thresholds = np.where(c_o + c_s >= 1)[0]\n",
    "    costs = 2 * c_o[valid_thresholds] - np.append(c_o[valid_thresholds[1:]], [1]) + c_s[valid_thresholds]\n",
    "    tau_star = valid_thresholds[np.argmin(costs)] / 255.0\n",
    "    return tau_star\n",
    "\n",
    "def estimate_scale(likelihood_map, object_hypothesis, tau):\n",
    "    segmentation = likelihood_map > tau\n",
    "    safe_region = np.zeros_like(segmentation)\n",
    "    top, left, bottom, right = object_hypothesis\n",
    "    safe_region[top:bottom, left:right] = True\n",
    "    safe_region[top+1:bottom-1, left+1:right-1] = False  # Inner 80% (approximated)\n",
    "    \n",
    "    labeled, num_features = ndimage.label(segmentation)\n",
    "    object_mask = np.zeros_like(segmentation)\n",
    "    \n",
    "    for label in range(1, num_features + 1):\n",
    "        component = labeled == label\n",
    "        if np.any(component & safe_region):\n",
    "            avg_likelihood = np.mean(likelihood_map[component])\n",
    "            if avg_likelihood > tau:\n",
    "                object_mask |= component\n",
    "    \n",
    "    if np.sum(object_mask) == 0:\n",
    "        return object_hypothesis\n",
    "    \n",
    "    rows, cols = np.where(object_mask)\n",
    "    top, bottom = np.min(rows), np.max(rows)\n",
    "    left, right = np.min(cols), np.max(cols)\n",
    "    return np.array([top, left, bottom, right])\n",
    "\n",
    "def generate_hypotheses(initial_hypothesis, scale_factors, translations, image_shape):\n",
    " \n",
    "    hypotheses = []\n",
    "    top, left, bottom, right = initial_hypothesis\n",
    "    height = bottom - top\n",
    "    width = right - left\n",
    "    \n",
    "    for scale in scale_factors:\n",
    "        # Scale the bounding box\n",
    "        new_height = int(height * scale)\n",
    "        new_width = int(width * scale)\n",
    "        \n",
    "        for dy, dx in translations:\n",
    "            # Translate the bounding box\n",
    "            new_top = max(0, top + dy)\n",
    "            new_left = max(0, left + dx)\n",
    "            new_bottom = min(image_shape[0], new_top + new_height)\n",
    "            new_right = min(image_shape[1], new_left + new_width)\n",
    "            \n",
    "            # Add the new hypothesis if it's within the image bounds\n",
    "            hypotheses.append((new_top, new_left, new_bottom, new_right))\n",
    "    \n",
    "    return hypotheses\n",
    "def compute_visual_score(likelihood_map, object_hypothesis):\n",
    "    top, left, bottom, right = object_hypothesis\n",
    "    return np.sum(likelihood_map[top:bottom, left:right])\n",
    "def compute_spatial_score(object_hypothesis, previous_center, sigma):\n",
    "\n",
    "    top, left, bottom, right = object_hypothesis\n",
    "    rows, cols = np.mgrid[top:bottom, left:right]\n",
    "    distances = (rows - previous_center[0])**2 + (cols - previous_center[1])**2\n",
    "    spatial_score = np.sum(np.exp(-distances / (2 * sigma**2)))\n",
    "    return spatial_score\n",
    "def find_best_hypothesis(likelihood_map, hypotheses, previous_center, sigma=10):\n",
    "    best_hypothesis = None\n",
    "    best_score = -np.inf\n",
    "\n",
    "    for hypothesis in hypotheses:\n",
    "        visual_score = compute_visual_score(likelihood_map, hypothesis)\n",
    "        spatial_score = compute_spatial_score(hypothesis, previous_center, sigma)\n",
    "        total_score = visual_score * spatial_score\n",
    "\n",
    "        if total_score > best_score:\n",
    "            best_score = total_score\n",
    "            best_hypothesis = hypothesis\n",
    "\n",
    "    return best_hypothesis\n",
    "def update_object_hypothesis(prev_hypothesis, scale_estimate, lambda_s,likelihood_map):\n",
    "    # Example usage\n",
    "    # initial_hypothesis = (100, 150, 200, 250)  # Example bounding box: (top, left, bottom, right)\n",
    "    scale_factors = [0.2, 1.0, .2]  # Scale down to 80%, keep original, scale up to 120%\n",
    "    translations = [(0, 0), (-5, -5), (5, 5), (-10, 0), (10, 0)]  # Various translations\n",
    "\n",
    "    # Assuming image shape is (height, width) \n",
    "    image_shape = (360, 640)  # Example image size\n",
    "    hypotheses = generate_hypotheses(prev_hypothesis, scale_factors, translations, image_shape)\n",
    "    best_hypothesis = find_best_hypothesis(likelihood_map, hypotheses, prev_hypothesis, sigma=10)\n",
    "    \n",
    "    return np.array( best_hypothesis)\n",
    "\n",
    "def update_object_model(frame, object_hypothesis):\n",
    "    top, left, bottom, right = object_hypothesis\n",
    "    object_region = frame[top:bottom, left:right]\n",
    "    hsv = cv2.cvtColor(object_region, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])\n",
    "    cv2.normalize(hist, hist, 0, 1, cv2.NORM_MINMAX)\n",
    "    return {'histogram': hist}\n",
    "\n",
    "def track_object(frames, initial_hypothesis, lambda_s=0.9, max_scale_change=0.2):\n",
    "    object_hypothesis = initial_hypothesis\n",
    "    object_model = None\n",
    "    \n",
    "    for frame in frames:\n",
    "        if object_model is None:\n",
    "            object_model = update_object_model(frame, object_hypothesis)\n",
    "        \n",
    "        likelihood_map = compute_likelihood_map(frame, object_hypothesis, object_model)\n",
    "        print(likelihood_map.shape,frame.shape)\n",
    "\n",
    "\n",
    "        top, left, bottom, right = object_hypothesis\n",
    "        object_region = (slice(top, bottom), slice(left, right))\n",
    "        surrounding_region = (slice(max(0, top-20), min(frame.shape[0], bottom+20)),\n",
    "                              slice(max(0, left-20), min(frame.shape[1], right+20)))\n",
    "        \n",
    "        c_o, c_s = compute_cumulative_histograms(likelihood_map, object_region, surrounding_region)\n",
    "        tau_star = adaptive_threshold(c_o, c_s)\n",
    "        \n",
    "        scale_estimate = estimate_scale(likelihood_map, object_hypothesis, tau_star)\n",
    "        \n",
    "        prev_area = np.prod(object_hypothesis[2:] - object_hypothesis[:2])\n",
    "        new_area = np.prod(scale_estimate[2:] - scale_estimate[:2])\n",
    "        \n",
    "        scale_change = np.abs(new_area / prev_area - 1)\n",
    "        print(object_hypothesis, scale_estimate,scale_change)\n",
    "        print(type(object_hypothesis))\n",
    "        if scale_change <= max_scale_change:\n",
    "            object_hypothesis = update_object_hypothesis(object_hypothesis, scale_estimate, lambda_s,likelihood_map)\n",
    "            # object_model = update_object_model(frame, object_hypothesis)\n",
    "        \n",
    "        yield frame, object_hypothesis, likelihood_map\n",
    "\n",
    "def main():\n",
    "    sequence_folder = 'sequence/'\n",
    "    frame_files = sorted([f for f in os.listdir(sequence_folder) if f.endswith('.jpg') or f.endswith('.png')])\n",
    "    \n",
    "    # Given object location\n",
    "    initial_bbox = (246, 208, 23, 23)  # Converted to integer pixel values for bounding box\n",
    "    \n",
    "    initial_hypothesis = np.array([initial_bbox[1], initial_bbox[0], \n",
    "                                   initial_bbox[1] + initial_bbox[3], \n",
    "                                   initial_bbox[0] + initial_bbox[2]])\n",
    "    \n",
    "    frames = (cv2.imread(os.path.join(sequence_folder, f)) for f in frame_files)\n",
    "    # for frame in frames:\n",
    "    #     cv2.imshow('Object Tracking', frame)\n",
    "    #     cv2.waitKey(0)\n",
    "    \n",
    "    for frame, object_hypothesis, likelihood_map in track_object(frames, initial_hypothesis):\n",
    "        vis_frame = frame.copy()\n",
    "        top, left, bottom, right = object_hypothesis\n",
    "        cv2.rectangle(vis_frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "        \n",
    "        color_map = cv2.applyColorMap((likelihood_map * 255).astype(np.uint8), cv2.COLORMAP_JET)\n",
    "        vis_likelihood = cv2.addWeighted(frame, 0.1, color_map, 0.9, 0)\n",
    "        \n",
    "        vis = np.hstack((vis_frame, vis_likelihood))\n",
    "        cv2.imshow('Object Tracking', vis)\n",
    "        # cv2.waitKey(0)\n",
    "        key = cv2.waitKey(0) & 0xFF\n",
    "        if key == 27:  # ESC key\n",
    "            break\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
